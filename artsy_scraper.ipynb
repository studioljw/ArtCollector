{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ArtsyCollector"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Objective \n",
    "To collect artwork data from Artsy.net"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1. Scrape links for all the artworks on sale currently"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import pprint\n",
    "import lxml\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "\n",
    "# specify the base URL\n",
    "BASE_URL = \"https://www.artsy.net/collect?page=1&acquireable=true&offerable=false&at_auction=false\"\n",
    "\n",
    "# launch the Selenium Chrome driver\n",
    "driver = webdriver.Chrome('chrome_driver/chromedriver')\n",
    "driver.get(BASE_URL)\n",
    "\n",
    "# find the total number of pages in this search\n",
    "page_nav = driver.find_elements_by_xpath('//div[@class=\"Box-sc-15se88d-0 iMqpar\"]')\n",
    "page_total = int(page_nav[-1].find_element_by_tag_name(\"a\").text)\n",
    "\n",
    "# specify the links data object\n",
    "links = []\n",
    "\n",
    "# loop over each page\n",
    "for i in range(page_total):\n",
    "\n",
    "    # open the page with Selenium\n",
    "    page_counter = i + 1\n",
    "    URL = \"https://www.artsy.net/collect?page=\" + str(page_counter) + \"&acquireable=true&offerable=false&at_auction=false\"\n",
    "    driver = webdriver.Chrome('chrome_driver/chromedriver')\n",
    "    driver.get(URL)\n",
    "    sleep(5)\n",
    "\n",
    "    # find all the artworks on the page\n",
    "    artworksOnPage = driver.find_elements_by_xpath('//div[@data-test=\"artworkGridItem\"]')\n",
    "\n",
    "    for entry in artworksOnPage:\n",
    "        # find all the links to those artworks on the page\n",
    "        links.append(entry.find_element_by_tag_name(\"a\").get_attribute(\"href\"))\n",
    "    \n",
    "    driver.close()\n",
    "    sleep(5)\n",
    "\n",
    "\n",
    "# print the total number of links we have\n",
    "print(len(links))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the links file to a separate .txt file for backup\n",
    "with open('links_list.txt', 'w') as filehandle:\n",
    "    for listitem in links:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "source": [
    "### 2. Scrape information from each of those artwork links"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the list of links\n",
    "links_list = []\n",
    "with open('links_list.txt', 'r') as filehandle:\n",
    "    for line in filehandle:\n",
    "        currentLink = line[:-1]\n",
    "        links_list.append(currentLink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import pprint\n",
    "import lxml\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "\n",
    "data = {\"page_URL\": [], \"artist\": [], \"artist_nationality\": [], \"artist_birthdate\": [], \"title\": [], \"image_URL\": [], \"year\": [], \"gallery\": [], \"gallery_location\": [], \"medium\": [], \"medium_details\": [], \"size_inches\": [], \"size_cm\": [], \"condition\": [], \"classification\": [], \"signed\": [], \"authenticated\": [], \"framed\": [], \"currency\": [], \"price\": []}\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('chrome_driver/chromedriver')\n",
    "\n",
    "# for diagnostics ONLY\n",
    "links_dummy = [\"https://www.artsy.net/artwork/karl-hartman-uncommon-crow\"]\n",
    "\n",
    "\n",
    "# loop over all entries in the links list\n",
    "\n",
    "for entry in links_list:\n",
    "    URL = entry\n",
    "    data[\"page_URL\"].append(URL)\n",
    "\n",
    "    driver = webdriver.Chrome('chrome_driver/chromedriver')\n",
    "    driver.get(URL)\n",
    "    sleep(2)\n",
    "\n",
    "    # extract information from image area\n",
    "\n",
    "    image_URL = driver.find_element_by_xpath('//img[@data-type=\"artwork-image\"]').get_attribute(\"src\")\n",
    "\n",
    "    # extract information from sidebar area\n",
    "\n",
    "    sidebar = driver.find_element_by_xpath('//div[@data-test=\"artworkSidebar\"]').text.split(\"\\n\")\n",
    "    data[\"image_URL\"].append(image_URL)\n",
    "    data[\"artist\"].append(sidebar[0])\n",
    "    data[\"title\"].append(sidebar[2].split(\", \")[0])\n",
    "    data[\"year\"].append(sidebar[2].split(\", \")[1])\n",
    "    data[\"medium_details\"].append(sidebar[3])\n",
    "    data[\"size_inches\"].append(sidebar[4])\n",
    "    data[\"size_cm\"].append(sidebar[5])\n",
    "    data[\"classification\"].append(sidebar[6])\n",
    "    data[\"currency\"].append(sidebar[7][0:1])\n",
    "    data[\"price\"].append(sidebar[7][1:])\n",
    "    data[\"gallery\"].append(sidebar[12])\n",
    "    data[\"gallery_location\"].append(sidebar[13])\n",
    "\n",
    "    # extract information from caption area\n",
    "\n",
    "    caption = driver.find_element_by_xpath('//div[@data-test=\"artworkDetails\"]').text.split(\"\\n\")\n",
    "\n",
    "    if \"Medium\" in caption:\n",
    "        index = caption.index(\"Medium\")\n",
    "        data[\"medium\"].append(caption[index+1])\n",
    "    else:\n",
    "        data[\"medium\"].append(\"NA\")\n",
    "\n",
    "    if \"Condition\" in caption:\n",
    "        index = caption.index(\"Condition\")\n",
    "        data[\"condition\"].append(caption[index+1])\n",
    "    else:\n",
    "        data[\"condition\"].append(\"NA\")\n",
    "\n",
    "    if \"Signature\" in caption:\n",
    "        index = caption.index(\"Signature\")\n",
    "        data[\"signed\"].append(caption[index+1])\n",
    "    else:\n",
    "        data[\"signed\"].append(\"NA\")\n",
    "\n",
    "    if \"Certificate of authenticity\" in caption:\n",
    "        index = caption.index(\"Certificate of authenticity\")\n",
    "        data[\"authenticated\"].append(caption[index+1])\n",
    "    else:\n",
    "        data[\"authenticated\"].append(\"NA\")\n",
    "\n",
    "    if \"Frame\" in caption:\n",
    "        index = caption.index(\"Frame\")\n",
    "        data[\"framed\"].append(caption[index+1])\n",
    "    else:\n",
    "        data[\"framed\"].append(\"NA\")\n",
    "\n",
    "    # extract information from artist bio area\n",
    "\n",
    "    bio = driver.find_element_by_xpath('//div[@data-test=\"artistInfo\"]').text.split(\"\\n\")\n",
    "\n",
    "    if \"b.\" in bio:\n",
    "        data[\"artist_nationality\"].append(bio[1].split(\", b. \")[0].translate({ord('•'): None}))\n",
    "        data[\"artist_birthdate\"].append(bio[1].split(\", b. \")[1][0:4].translate({ord('•'): None}))\n",
    "    else:\n",
    "        data[\"artist_nationality\"].append(bio[1].translate({ord('•'): None}))\n",
    "        data[\"artist_birthdate\"].append(\"NA\")\n",
    "    \n",
    "\n",
    "    # close the open window\n",
    "    print(index(entry))\n",
    "    driver.close()\n",
    "    sleep(2)\n",
    "\n",
    "\n",
    "# quit driver and print data\n",
    "\n",
    "driver.quit()\n",
    "print(len(data))\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "source": [
    "### 3. Attempt a quicker solution with Beautiful Soup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://d32dm0rphc51dk.cloudfront.net/Av-Aaqu_JwskxttJT4z_Vg/large.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://www.artsy.net/artwork/karl-hartman-uncommon-crow\"\n",
    "http = urllib3.PoolManager()\n",
    "\n",
    "response = http.request('GET', URL)\n",
    "soup = BeautifulSoup(response.data, \"lxml\")\n",
    "\n",
    "image_URL = soup.img['src']\n",
    "print(image_URL)\n",
    "\n",
    "sidebar = driver.find_element_by_xpath('//div[@data-test=\"artworkSidebar\"]').text.split(\"\\n\")\n",
    "    data[\"image_URL\"].append(image_URL)\n",
    "    data[\"artist\"].append(sidebar[0])\n",
    "    data[\"title\"].append(sidebar[2].split(\", \")[0])\n",
    "    data[\"year\"].append(sidebar[2].split(\", \")[1])\n",
    "    data[\"medium_details\"].append(sidebar[3])\n",
    "    data[\"size_inches\"].append(sidebar[4])\n",
    "    data[\"size_cm\"].append(sidebar[5])\n",
    "    data[\"classification\"].append(sidebar[6])\n",
    "    data[\"currency\"].append(sidebar[7][0:1])\n",
    "    data[\"price\"].append(sidebar[7][1:])\n",
    "    data[\"gallery\"].append(sidebar[12])\n",
    "    data[\"gallery_location\"].append(sidebar[13])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class ImageSpider(scrapy.Spider):\n",
    "\n",
    "    name: 'images'\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "            'https://www.artsy.net/artwork/karl-hartman-uncommon-crow'\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "    \n",
    "    def parse(self, response):\n",
    "        page = response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## API solution\n",
    "\n",
    "import requests\n",
    "\n",
    "headers = {'X-Auth-Token': 'eyJhbGciOiJIUzI1NiJ9.eyJyb2xlcyI6IiIsInN1YmplY3RfYXBwbGljYXRpb24iOiI2MDE0NDk3MjNlZjg1MjAwMTE3YTBiNGUiLCJleHAiOjE2MTI1NDcwNTksImlhdCI6MTYxMTk0MjI1OSwiYXVkIjoiNjAxNDQ5NzIzZWY4NTIwMDExN2EwYjRlIiwiaXNzIjoiR3Jhdml0eSIsImp0aSI6IjYwMTQ0OTczODNkMmEyMDAxMTFjZDBiNiJ9.Jb7HeMLSEsdEO69PxqM80B4pEqGqxPzFg2cYUE9TfyI'}\n",
    "\n",
    "r = requests.get(\"https://api.artsy.net/api/sales\", headers=headers)\n",
    "r.json()"
   ]
  }
 ]
}